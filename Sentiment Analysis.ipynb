{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b5a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e2db21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b9d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence):\n",
    "    sentence=re.sub(r'#[A-Za-z0-9]\\S+','', sentence)\n",
    "    sentence=re.sub(r'http\\S+', '', sentence)\n",
    "    sentence=re.sub(r'@[A-Za-z0-9]\\S+','',sentence)\n",
    "    sentence=\" \".join(word for word in sentence.split() if len(word)>3)\n",
    "    return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e43132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           id  label                                              tweet\n",
       "0          1      0  when father dysfunctional selfish drags kids i...\n",
       "1          2      0  thanks credit can't cause they don't offer whe...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  love take with time urð±!!! ðððð ...\n",
       "4          5      0                                factsguide: society\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  that youuu?ððððððððð...\n",
       "31958  31959      0  nina turner airwaves trying wrap herself mantl...\n",
       "31959  31960      0                listening songs monday morning work\n",
       "31960  31961      1                                vandalised condemns\n",
       "31961  31962      0                                       thank follow\n",
       "\n",
       "[31962 rows x 3 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']=df['tweet'].map(cleanSentence)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac9a711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['when',\n",
       "  'father',\n",
       "  'dysfunctional',\n",
       "  'selfish',\n",
       "  'drags',\n",
       "  'kids',\n",
       "  'into',\n",
       "  'dysfunction',\n",
       "  '',\n",
       "  'thanks'],\n",
       " 238049)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of Words\n",
    "words=[]\n",
    "for sentences in df['tweet']:\n",
    "    words.extend(re.split(r'\\W+',sentences))\n",
    "words[:10],len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13162e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sadan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20380"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "words=set([lemmatizer.lemmatize(word.lower()) for word in words])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1daf1645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Training Set\n",
    "train_x=[]\n",
    "words=list(words)\n",
    "for sentence in df.tweet:\n",
    "    word=set([word.lower() for word in sentence.split(\" \")])\n",
    "    temp=[]\n",
    "    for w in words:\n",
    "        temp.append(1 if w in word else 0)\n",
    "    train_x.append(temp)\n",
    "train_x[0].index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022e6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_x\n",
    "Y=df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e328dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f66ec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5114/5114 [==============================] - 601s 62ms/step - loss: 0.2610 - accuracy: 0.9311\n",
      "Epoch 2/5\n",
      "5114/5114 [==============================] - 330s 65ms/step - loss: 0.2508 - accuracy: 0.9328\n",
      "Epoch 3/5\n",
      "5114/5114 [==============================] - 337s 66ms/step - loss: 0.2618 - accuracy: 0.9332\n",
      "Epoch 4/5\n",
      "5114/5114 [==============================] - 326s 64ms/step - loss: 0.2570 - accuracy: 0.9334\n",
      "Epoch 5/5\n",
      "5114/5114 [==============================] - 323s 63ms/step - loss: 0.2507 - accuracy: 0.9338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2023277d6d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Model\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(Dense(500,input_shape=(len(words),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "adam=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "model.fit(np.array(X_train),np.array(Y_train),epochs=5,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d726948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347724073205068"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the Model\n",
    "count=0\n",
    "for i in range(len(X_test)):\n",
    "    prediction=model.predict(np.array([X_test[i]]))[0][0]\n",
    "    if prediction>0.5 and np.array(Y_test)[i]==1:\n",
    "        count+=1\n",
    "    elif prediction<=0.5 and np.array(Y_test)[i]==0:\n",
    "        count+=1\n",
    "        \n",
    "count/len(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
